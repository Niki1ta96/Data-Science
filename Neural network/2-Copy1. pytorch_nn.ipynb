{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6,15,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d (6, 15, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120)\n",
       "  (fc2): Linear(in_features=120, out_features=84)\n",
       "  (fc3): Linear(in_features=84, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "param = list(net.parameters())\n",
    "#print(param)\n",
    "print(len(param))\n",
    "print(param[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       " -0.6942 -1.5305 -0.0919  ...   1.1585 -1.1838 -1.5291\n",
       "  1.0865  0.4666 -1.0670  ...   1.9313 -0.5371  0.6627\n",
       "  0.1947  0.6698  0.4105  ...  -1.5660  0.7879  1.1434\n",
       "           ...             ⋱             ...          \n",
       "  0.9158  1.0929  0.1171  ...  -0.0980 -0.6740 -1.2711\n",
       "  1.3006 -1.3908 -0.4397  ...  -0.8409  0.2024  0.6765\n",
       "  0.9412 -0.7685  1.8606  ...  -0.3987  0.6987 -0.9139\n",
       "[torch.FloatTensor of size 1x1x32x32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,32,32))\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120)\n",
      "  (fc2): Linear(in_features=120, out_features=84)\n",
      "  (fc3): Linear(in_features=84, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0202 -0.0006  0.0502  0.0801  0.1233 -0.0306  0.0187  0.0380 -0.0985  0.0769\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120)\n",
       "  (fc2): Linear(in_features=120, out_features=84)\n",
       "  (fc3): Linear(in_features=84, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.2563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.arange(1,11))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f1d59303cc0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddmmBackward object at 0x7f1d6c156c18>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExpandBackward object at 0x7f1d6c103748>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -6.3835\n",
      " -4.2272\n",
      " -2.7133\n",
      " -1.9252\n",
      "  2.2236\n",
      "  2.2399\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0925  0.0922 -0.0192 -0.0864 -0.0189\n",
       "  -0.0247 -0.1674  0.0085  0.0797  0.1546\n",
       "  -0.1720 -0.0154  0.1709 -0.0915  0.1874\n",
       "   0.0447 -0.1285 -0.0339 -0.1926  0.0246\n",
       "  -0.1246  0.1604 -0.0717  0.1736  0.0851\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -0.0327  0.0834 -0.1257 -0.0210 -0.1381\n",
       "  -0.0698 -0.0799 -0.0607 -0.0886 -0.0157\n",
       "  -0.1498 -0.1427 -0.1823  0.0107 -0.0035\n",
       "   0.1780  0.0916  0.1774  0.1672  0.1471\n",
       "  -0.1979  0.0728  0.0179  0.0420  0.1083\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.1373 -0.0740 -0.1030  0.0666  0.0156\n",
       "  -0.1180  0.1460  0.0693 -0.0391  0.1883\n",
       "  -0.0161 -0.1292  0.0277 -0.1514  0.0012\n",
       "  -0.1018  0.0023  0.0763  0.0961  0.0301\n",
       "   0.1791  0.1040 -0.0032  0.1868 -0.0663\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "  -0.1180  0.0819 -0.1447 -0.1249  0.1745\n",
       "  -0.1220 -0.0927  0.0440  0.0152 -0.0046\n",
       "  -0.1224  0.1593  0.0883  0.1939 -0.0638\n",
       "  -0.1402 -0.1120 -0.1136  0.1462 -0.1696\n",
       "  -0.0071 -0.0384 -0.0625  0.0835 -0.0112\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "  -0.1981 -0.1976 -0.1026  0.1756 -0.1226\n",
       "  -0.0154 -0.1353 -0.1525  0.0244 -0.0934\n",
       "   0.0972  0.0924 -0.0697  0.0775 -0.0860\n",
       "  -0.0147 -0.1704 -0.1617 -0.1373  0.1098\n",
       "  -0.1732  0.0080  0.0403  0.0660  0.0253\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.0826  0.1144  0.1987 -0.0370  0.0793\n",
       "  -0.1427 -0.0013  0.1283 -0.0094 -0.1717\n",
       "   0.0028 -0.1538  0.0106 -0.1739 -0.1889\n",
       "   0.0359 -0.0453 -0.1520 -0.1472 -0.0844\n",
       "  -0.1165 -0.0346 -0.1917  0.0432  0.0008\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       " -0.1555\n",
       "  0.0724\n",
       "  0.1537\n",
       "  0.0762\n",
       "  0.1011\n",
       " -0.1757\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.3574 -4.2677  7.4972  2.8472  2.4433\n",
       "  -0.2019  1.0648 -0.4185  5.8230 -4.8365\n",
       "   5.2019  1.9052 -3.9686 -5.7647  0.5434\n",
       "   5.4969 -5.9693 -1.2034  5.7054  1.2877\n",
       "   1.7327  3.4569  6.8123 -3.2130  5.2798\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.2444 -0.5714 -4.8048 -4.0770 -1.5423\n",
       "   5.2535 -3.6553  3.9678 -2.7180 -0.0884\n",
       "   1.5901  0.8591  6.9631 -5.0892 -1.4887\n",
       "   4.4304  3.1824 -7.0566  7.1326  4.2946\n",
       "   0.7677  3.9070 -7.6816 -2.0913 -6.9467\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.8886  4.1994  2.2426 -4.8719 -0.0170\n",
       "   6.2063 -4.0630  3.4519 -7.4534  7.1133\n",
       "   6.3837 -3.0288  7.8860 -0.0909 -1.3827\n",
       "  -0.1789 -1.7146  5.4286  1.5439 -0.3100\n",
       "  -5.4843 -0.7929  2.1264  3.6330 -4.8023\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.0545 -8.1440  2.5235  5.2523  2.4785\n",
       "   2.4997  2.3710 -1.2138  0.1916  2.6055\n",
       "  -6.2410 -2.1491 -2.2118  2.8415 -7.3468\n",
       "  -5.8775  2.1322 -7.1837  3.7952  1.2855\n",
       "   5.9062  8.0043  3.5707 -0.2060 -3.1503\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.1034  2.9420 -6.9905  6.7049  1.9522\n",
       "   6.7407  0.9930  6.9075 -6.8024  3.8670\n",
       "   6.3295  7.8458 -6.1673 -0.9960  5.8405\n",
       "   0.2787  4.0355  4.2649 -6.0639  0.4974\n",
       "  -2.2982  5.4543  0.6292  4.6478  2.8065\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.1458  0.8486 -1.7595  8.1562 -4.1639\n",
       "   0.2998  6.8040 -7.9355  1.4421 -3.8504\n",
       "  -6.8863  6.8614  4.5448 -2.8028 -3.8917\n",
       "  -5.5682  3.3403 -3.1926 -5.2279  1.9515\n",
       "   0.9398  2.8118 -3.2872 -0.6681 -0.7233\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.1877  1.6507 -2.6581  6.8788 -5.7962\n",
       "   2.5645  2.1948 -3.5828 -0.2884 -7.4099\n",
       "   3.7770 -1.0810 -2.3878 -6.6604 -1.7000\n",
       "  -5.3231  7.2763  3.9891  1.2619 -3.0511\n",
       "  -3.8794 -7.9441 -8.0718  5.0018  3.6996\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.6120  5.1660  2.9720  5.2981  0.3053\n",
       "   5.3681 -8.0360 -7.4949 -2.4441  1.4590\n",
       "   3.4798  2.8323  0.6585  6.1426  1.0782\n",
       "   8.0162 -6.6790  2.5516 -2.1902  3.6343\n",
       "   2.6698  1.0664 -0.2303  0.4200  4.7040\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.5148 -7.8651  0.3431 -1.9715 -3.9873\n",
       "  -7.5895  4.8130 -1.8716  5.7290  8.1478\n",
       "  -1.2824  6.9879  5.8212  0.8597  3.3105\n",
       "   2.9277  1.3795  5.4313  5.5219 -0.6826\n",
       "   1.1312  2.7267 -5.7791  8.0433  0.9032\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.4705 -1.7626 -0.9972 -2.4986 -4.0766\n",
       "   6.8159 -5.9519  3.9606  3.9199  5.0825\n",
       "  -3.5053  4.0637  6.3154  4.6096 -1.1320\n",
       "   0.4891  2.8167  3.4916 -5.1993  5.2779\n",
       "   6.1628  4.4032 -4.9160 -6.9378  6.5246\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.6158  7.8449  2.1681  2.4859 -6.7804\n",
       "   0.4862 -1.2124 -2.8627  2.3883 -4.2595\n",
       "   1.9337 -3.1626  2.5636  0.4829 -4.8550\n",
       "   5.2091 -7.7522 -2.8659 -3.9466 -0.5441\n",
       "  -2.0804 -3.8089 -7.5909  1.0905 -6.2878\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.2774 -1.8692  3.5858  4.3352  1.7286\n",
       "   2.6718 -7.4525 -6.9300  5.3556  4.0144\n",
       "   3.6241 -3.0701  2.5652  0.5470  0.5757\n",
       "   0.1329  1.1233  3.2329  4.5896 -3.9662\n",
       "  -7.3604  1.7687 -0.0460 -5.0373 -1.4078\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.5223 -1.6618 -5.9506 -2.4312  5.0958\n",
       "   0.3895  0.9214  5.3099  0.9138  0.1712\n",
       "  -4.7070 -6.0760 -7.0562 -0.8793 -2.1416\n",
       "   3.2386  0.3227 -6.4036  6.6110  7.4686\n",
       "   0.9294 -2.2319  1.2207 -5.1726  1.1003\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.7411 -5.5115 -7.2563  3.6225 -2.8841\n",
       "  -0.8419  5.0883 -6.2071  4.1507 -5.1842\n",
       "  -4.0274 -1.9871 -5.9271  3.8941  1.2236\n",
       "   4.0316 -0.0933  0.4093 -3.6199  3.5348\n",
       "   0.9662 -7.4955 -4.3156 -6.3086 -5.9210\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.7706  0.8318 -3.8432 -2.8793 -0.6861\n",
       "  -6.1324  6.6422 -0.4329  6.7388  4.4386\n",
       "   0.5835 -4.4517  8.1645  7.4714  4.0000\n",
       "  -0.3382  8.1203 -7.0150  6.9394 -5.8970\n",
       "   2.1651 -7.9067 -7.3591  3.6798 -8.1371\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.2130  0.2270 -7.6734  2.7776 -1.3475\n",
       "  -2.7253 -5.4520  5.9667 -2.3375  0.2385\n",
       "   2.2339  5.8664  2.6191 -4.5827 -5.2425\n",
       "  -4.1262  3.9379  0.8308 -6.0210  4.8917\n",
       "   5.8646 -1.3962 -1.5956 -5.8799 -3.7322\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.1392  8.0223 -3.6108 -2.5123  7.3057\n",
       "   3.0610 -8.1575 -0.7522  3.2007 -5.3433\n",
       "  -3.5369 -7.5885 -5.5636 -0.0114  1.5813\n",
       "  -1.4256 -0.7773 -1.6943  4.8169 -6.9486\n",
       "   1.4062  6.8948  1.0029 -0.2439 -8.0513\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.7742 -0.9520  4.2927  4.3526 -3.3645\n",
       "  -6.3370 -4.4928  6.5985  7.2068 -6.8711\n",
       "  -1.7949 -0.1721  0.4831  0.1648  2.0897\n",
       "  -5.8626  6.5706 -7.9573  1.1896 -1.4027\n",
       "  -6.5188 -6.9974 -4.7787  7.1336 -3.0562\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.5130 -1.2351 -7.8546  7.1113 -0.1093\n",
       "   5.6028  6.1865 -1.8950 -0.9454  0.4300\n",
       "   1.4415  1.0714 -2.3837 -2.1577  6.3098\n",
       "   2.8245  1.1603  1.5325  7.9620 -0.8854\n",
       "  -2.2182 -2.3587 -3.8778 -3.1913 -5.4781\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.3247 -4.3941 -6.6839  1.5391  0.8941\n",
       "  -1.3172  7.0575  7.3566 -2.0830  6.9017\n",
       "   5.8996 -6.6284  3.8778 -4.8798 -0.7968\n",
       "  -4.7928 -7.1418  6.1504 -1.3307 -3.4409\n",
       "  -7.7190 -2.7960  2.4731 -2.6907  4.1002\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.1043 -3.7413 -3.1960 -1.1801  5.5932\n",
       "  -3.6616  7.8194 -5.2355 -4.0729  4.8225\n",
       "  -3.2853 -0.7511  5.4952 -4.6035 -5.0214\n",
       "  -4.2449  7.1125 -2.5231  8.0799  3.3778\n",
       "   2.1258  4.0726  2.4546 -0.6090  3.0592\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.4156  7.9596  8.0567 -6.0419 -1.4277\n",
       "  -5.9335 -4.5084  1.6171 -2.1310  6.8864\n",
       "  -4.0886  7.6140 -6.4806  6.0492  0.8335\n",
       "   1.5908  1.2417  2.3820 -5.8773 -1.0715\n",
       "   5.6597  5.1225 -3.6583 -4.6893  6.3233\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.4287 -6.8712 -7.3374  3.3060  1.2220\n",
       "  -5.4998 -6.5454 -6.5601 -8.0742  1.2192\n",
       "   3.3716  0.8525 -5.4066 -5.2554 -7.9906\n",
       "  -3.5388  2.3387 -2.7591  7.1275 -1.9039\n",
       "  -7.5280 -7.6693 -5.3486 -3.6061 -3.1780\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.2887  3.0102  7.0150  6.3755 -2.9413\n",
       "   0.8926  4.9829 -0.5716 -6.8900  7.3887\n",
       "  -3.1456  4.0114  6.1475 -0.7801 -5.0602\n",
       "   2.1622  0.7010 -1.9036  7.0237  5.5781\n",
       "   1.6502 -0.7303 -8.1256 -2.5083  5.4714\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   1.2324  6.3106 -3.2022 -4.8564 -6.4442\n",
       "   3.8337  4.8339 -7.5202 -5.9534 -1.3562\n",
       "   5.9846 -7.9188  1.9283  0.4953 -0.6092\n",
       "   2.1099 -7.9920  5.5722 -5.6629 -7.6904\n",
       "   7.2453 -0.3333 -6.6380 -6.8816  5.3574\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.0715  5.6891  5.7289 -1.5729 -6.1760\n",
       "   6.0087  6.3838 -2.8646  5.9299  1.1460\n",
       "  -6.6085  6.4004 -0.7381  7.3050 -0.2411\n",
       "   2.3443  2.9327  3.4664  3.7870 -0.6115\n",
       "   6.1984 -2.9007 -7.4010  4.5710  5.1926\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.7108 -6.6279  0.3255  7.3782  6.0029\n",
       "  -3.3472 -7.2040  2.7998 -2.1966 -0.7139\n",
       "  -0.7285  7.6063  5.6770  6.7185 -8.0033\n",
       "  -7.0237  4.3570  3.5316  7.3459 -6.4090\n",
       "  -3.8050 -7.0101 -1.1997  8.0973  1.8519\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.9066 -1.9730 -1.8801  4.5520 -3.2563\n",
       "  -7.9147 -1.5125  3.7090 -5.8855  6.0858\n",
       "   7.6209  0.6463 -2.4127  0.6815 -2.8833\n",
       "   1.4219  5.8667 -2.5843 -3.7525 -6.9612\n",
       "  -7.2903 -0.9296 -3.1448 -7.0171 -5.4298\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.1050  7.3280  3.7231  5.0329 -4.2703\n",
       "  -1.0124  6.6465 -7.2256  7.5771  0.2637\n",
       "  -1.1502 -4.6550 -6.4684 -4.0231  1.3354\n",
       "   3.4249  3.7961 -4.9144 -4.0700 -2.7734\n",
       "  -4.2328 -2.2462 -6.4747 -6.7516  6.4092\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.4658 -5.2064  5.5000  1.3009 -8.0090\n",
       "  -7.8257 -6.5295 -0.1245  4.6937  1.3557\n",
       "   4.1257 -1.4835 -0.2020  5.8015  2.4428\n",
       "  -0.1951  2.6014  5.9803 -2.0853 -7.0026\n",
       "  -0.2756 -0.2641 -6.6075 -5.9002  3.0033\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.9428  7.9474 -6.8345  4.8772 -0.1361\n",
       "   0.8384  0.9283 -2.3415 -1.2708  5.4164\n",
       "   3.1965  1.0311 -7.2080  4.4178  5.1130\n",
       "   2.8489 -4.5339 -0.8472 -4.1685  2.5171\n",
       "   7.7938 -7.0837  5.3224  1.6669  1.1711\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.6314  2.8710  4.7940  5.3664  4.5232\n",
       "  -1.4043 -1.4630 -0.1184 -7.9614 -3.8061\n",
       "  -6.2756  3.4019  7.8108  3.1474 -5.5248\n",
       "   4.6109 -0.5275 -4.9216 -5.9366  5.9483\n",
       "  -0.5885  0.3465  7.2089 -2.0144  8.1611\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.0166 -2.5631  3.8994 -7.4597  1.1070\n",
       "   2.3254  7.0066  3.0743 -4.4421 -4.8894\n",
       "   4.3906  0.1445 -7.0404 -6.9532  5.9105\n",
       "  -4.6215  6.2076 -3.6048 -1.8827  1.8404\n",
       "   2.9239 -2.3065 -3.4428 -1.0340 -7.6644\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.0490  2.9638 -2.7758 -6.8342 -1.2751\n",
       "  -5.5829  5.0094 -1.1622  7.7997  6.1691\n",
       "   0.7924  2.9451  2.2953 -6.8099  7.7050\n",
       "   1.1089  7.9214  2.8431  6.4671  0.4478\n",
       "   2.0506  3.9171 -0.6106  0.0045  1.6939\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.8705  3.4249  4.0716 -2.4593  5.2614\n",
       "  -0.9638 -0.8722  8.0632 -6.3914 -1.1050\n",
       "   2.8731 -0.9259  0.3314  1.9452 -3.9443\n",
       "   4.9351  5.9846 -1.9454 -3.9295 -5.1477\n",
       "  -1.2590 -3.0098  0.8763  5.7245  2.3763\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.1042  4.8708  7.8586  1.3719 -0.6599\n",
       "  -7.5175 -7.1132  3.1724 -6.3240  7.5969\n",
       "   7.2458  5.3739 -5.4859 -4.4626  4.8179\n",
       "  -2.6584 -7.3480 -5.5615 -0.9265 -2.7220\n",
       "  -4.2826  5.8921  1.4196  0.2260  0.1176\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -6.2287\n",
       "   1.6521\n",
       "   5.9964\n",
       "   4.5897\n",
       "   5.2199\n",
       "  -0.3805\n",
       "  -7.7895\n",
       "  -1.0578\n",
       "   5.6819\n",
       "  -6.7595\n",
       "   6.8304\n",
       "   3.2216\n",
       "   5.7167\n",
       "  -5.4473\n",
       "   4.1724\n",
       "   6.8938\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       " -2.2642e-02 -2.1856e-02  2.5729e-02  ...   1.9551e-02 -3.1744e-02 -4.5435e-02\n",
       "  2.9465e-02  5.0700e-03  1.7604e-03  ...   4.9742e-02  4.0115e-02  3.2131e-03\n",
       "  2.7574e-02  7.7493e-03  3.3455e-02  ...   4.1352e-02  3.3955e-02  1.8412e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -3.3196e-02  4.5754e-02  1.6597e-02  ...  -3.5011e-03  4.9873e-03  4.5771e-02\n",
       " -3.7245e-02 -5.4685e-03 -3.9319e-02  ...   4.7008e-02 -2.6504e-02  4.5395e-03\n",
       "  8.9313e-03 -4.5174e-02  4.4675e-02  ...  -9.6286e-03  4.5955e-02  1.3134e-02\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -2.9634\n",
       "   3.9045\n",
       "   4.9606\n",
       "   4.0336\n",
       "   1.4378\n",
       "  -2.8618\n",
       "  -0.1760\n",
       "  -2.6362\n",
       "   3.7294\n",
       "   2.0124\n",
       "   4.5857\n",
       "  -2.7203\n",
       "  -1.6350\n",
       "   1.7138\n",
       "  -1.2775\n",
       "   3.6682\n",
       "  -4.8428\n",
       "   2.1354\n",
       "  -1.5948\n",
       "   2.6909\n",
       "   2.4622\n",
       "   0.9402\n",
       "  -1.9114\n",
       "   1.1295\n",
       "   3.5194\n",
       "   2.7399\n",
       "   3.3758\n",
       "   0.3442\n",
       "   3.0498\n",
       "   4.0925\n",
       "  -3.4379\n",
       "  -2.5596\n",
       "  -4.8115\n",
       "   0.1327\n",
       "   2.9447\n",
       "  -2.8163\n",
       "   1.2922\n",
       "  -1.2231\n",
       "  -2.6106\n",
       "   1.1547\n",
       "   3.2641\n",
       "   0.0991\n",
       "  -2.6728\n",
       "   4.6682\n",
       "  -2.7958\n",
       "   3.4122\n",
       "   4.6832\n",
       "   4.2829\n",
       "  -4.5274\n",
       "  -1.0486\n",
       "   4.9180\n",
       "  -4.6630\n",
       "  -0.1934\n",
       "   3.1093\n",
       "  -2.0942\n",
       "   3.4791\n",
       "  -4.6613\n",
       "  -0.7919\n",
       "   4.6262\n",
       "  -1.7033\n",
       "   2.5822\n",
       "  -0.7678\n",
       "  -1.1195\n",
       "   4.7816\n",
       "  -4.7022\n",
       "   3.0641\n",
       "  -0.9115\n",
       "  -1.2780\n",
       "   1.9550\n",
       "  -1.3747\n",
       "  -0.9583\n",
       "   3.5963\n",
       "  -4.8172\n",
       "   1.5501\n",
       "  -3.2309\n",
       "  -4.4034\n",
       "  -0.7216\n",
       "   0.4344\n",
       "   1.4011\n",
       "   3.1802\n",
       "   4.8628\n",
       "   0.8571\n",
       "   1.3358\n",
       "   4.5573\n",
       "  -0.3518\n",
       "  -0.1953\n",
       "  -3.1056\n",
       "  -2.5688\n",
       "   0.5925\n",
       "   0.5331\n",
       "   0.4397\n",
       "   1.0839\n",
       "  -1.1315\n",
       "  -2.1728\n",
       "   0.7501\n",
       "   2.4173\n",
       "  -0.7658\n",
       "   3.6148\n",
       "  -3.8952\n",
       "  -2.6129\n",
       "   4.6048\n",
       "   0.0969\n",
       "  -1.9307\n",
       "  -0.5109\n",
       "  -1.3240\n",
       "  -2.4931\n",
       "   2.9621\n",
       "  -2.5975\n",
       "  -3.2295\n",
       "   4.7849\n",
       "   1.9129\n",
       "  -2.0364\n",
       "  -2.1688\n",
       "   4.5380\n",
       "   0.0214\n",
       "  -2.5473\n",
       "   2.7872\n",
       "  -1.2329\n",
       "   3.0352\n",
       "  -2.0599\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  1.7296 -2.9925  2.2504  ...  -6.4114  3.4914  8.9929\n",
       "  3.4543 -1.2634  5.0236  ...   8.7761 -5.6414 -1.5589\n",
       " -4.7899  5.4371 -3.7943  ...   5.7703 -8.2935  6.3358\n",
       "           ...             ⋱             ...          \n",
       "  7.4766 -8.6348 -6.5774  ...   3.2478 -4.4583  8.7260\n",
       " -3.6605 -5.2310 -3.8120  ...  -4.9970 -7.2612  3.4425\n",
       "  4.4958 -7.2076 -1.0884  ...   4.3948 -1.2109  5.0154\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -6.8785\n",
       "   8.7522\n",
       "  -0.6273\n",
       "   7.9204\n",
       "  -2.9704\n",
       "  -6.9376\n",
       "  -7.4571\n",
       "   1.0171\n",
       "  -6.6035\n",
       "  -3.4526\n",
       "   0.0290\n",
       "   8.9440\n",
       "  -6.1185\n",
       "  -5.1255\n",
       "   0.1388\n",
       "   4.4258\n",
       "   2.9755\n",
       "   5.5097\n",
       "   6.4756\n",
       "   4.3423\n",
       "   0.4010\n",
       "  -8.9325\n",
       "   1.3959\n",
       "   7.5059\n",
       "  -3.6597\n",
       "  -3.0013\n",
       "   0.8828\n",
       "   4.6399\n",
       "   5.6496\n",
       "   3.4437\n",
       "   1.9316\n",
       "   3.7009\n",
       "   1.9986\n",
       "  -4.0214\n",
       "  -7.1035\n",
       "   0.4584\n",
       "   5.4887\n",
       "   2.4371\n",
       "  -8.9502\n",
       "   0.0781\n",
       "  -7.6879\n",
       "  -9.0484\n",
       "   8.2882\n",
       "  -8.8639\n",
       "   1.2756\n",
       "  -2.4476\n",
       "  -7.9431\n",
       "  -0.4891\n",
       "   3.2214\n",
       "  -1.3829\n",
       "   2.6359\n",
       "  -1.9851\n",
       "  -0.8802\n",
       "   7.7850\n",
       "   4.5226\n",
       "   8.7707\n",
       "   3.9157\n",
       "  -1.1284\n",
       "   6.6357\n",
       "  -1.3471\n",
       "   2.0581\n",
       "   3.0986\n",
       "   5.8983\n",
       "   5.9127\n",
       "  -0.1221\n",
       "  -8.8770\n",
       "  -7.1918\n",
       "   8.5442\n",
       "  -7.7307\n",
       "   3.9392\n",
       "   5.4656\n",
       "   8.3449\n",
       "   8.2392\n",
       "  -0.6039\n",
       "  -4.6051\n",
       "   0.0115\n",
       "  -8.0800\n",
       "  -1.4938\n",
       "  -7.6623\n",
       "   2.9090\n",
       "   4.5194\n",
       "  -7.4923\n",
       "   4.8702\n",
       "  -5.8558\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       "  0.0910 -0.0146 -0.0496  0.0958 -0.0774 -0.0442 -0.0937  0.0833 -0.0985  0.0879\n",
       "  0.0028 -0.0181  0.0712  0.0035  0.0276  0.0208  0.0136  0.1013  0.0094  0.0526\n",
       "  0.0268  0.0681  0.0242  0.0858  0.0458  0.0141  0.0961  0.1066  0.0981 -0.0157\n",
       " -0.0407 -0.0541 -0.0374  0.0435  0.0150 -0.0340  0.1026 -0.0753 -0.0056  0.0820\n",
       " -0.1045 -0.0765  0.0251  0.0796 -0.0942 -0.0135  0.0129 -0.0592 -0.0863 -0.0127\n",
       "  0.0256 -0.0992  0.0601  0.0481  0.0980 -0.0735 -0.0035 -0.0079  0.0769 -0.0704\n",
       " -0.0451 -0.0801 -0.0986 -0.0652 -0.0631 -0.0502  0.1080 -0.0885  0.0057  0.0788\n",
       " -0.0996  0.0158  0.0848 -0.0620  0.0669 -0.0050 -0.0520 -0.0918 -0.1044 -0.0593\n",
       "  0.0006 -0.0553  0.0663 -0.0480 -0.1075  0.0123  0.0042 -0.0476  0.0596 -0.0537\n",
       " -0.0465 -0.0138  0.0508 -0.0112 -0.0509 -0.0141 -0.0425 -0.0795  0.0543 -0.0470\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.1041 -0.0374 -0.0473  0.0026 -0.1083 -0.1043 -0.0344 -0.0575  0.0457  0.0320\n",
       " -0.0939  0.0025 -0.0556 -0.0387  0.0830 -0.0904 -0.0325 -0.0265  0.0647 -0.0693\n",
       " -0.0149 -0.0128 -0.0372 -0.0646 -0.0670 -0.0771 -0.0091  0.0328 -0.0856  0.0934\n",
       "  0.0252  0.0090  0.0463 -0.0070  0.0711 -0.0245 -0.0513 -0.0958 -0.0274  0.0065\n",
       " -0.0142 -0.0582 -0.0914  0.0353 -0.0668  0.0977 -0.0577  0.0336  0.0038  0.0329\n",
       " -0.1006 -0.0134 -0.0113 -0.0718 -0.0182 -0.0389 -0.0544 -0.0665 -0.0197 -0.0740\n",
       "  0.1046 -0.0283  0.0231 -0.0211  0.0281  0.0694  0.0713  0.0502  0.1029 -0.0630\n",
       " -0.1055  0.0332  0.0904 -0.0941 -0.0056 -0.0324 -0.0662  0.0526 -0.1075 -0.1010\n",
       "  0.0964 -0.0150  0.0138  0.0617 -0.0182  0.0636 -0.0459 -0.0688 -0.0107 -0.0153\n",
       "  0.0672 -0.0951 -0.0770 -0.0480 -0.0343  0.0584 -0.0017  0.0424  0.0164 -0.0244\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.0528  0.0014  0.0989 -0.0405 -0.0526 -0.0338  0.0761 -0.0493 -0.0003 -0.1037\n",
       "  0.1082 -0.0412 -0.0102 -0.0730 -0.0315 -0.0786  0.0022  0.0986 -0.0019  0.1087\n",
       "  0.0612  0.1015 -0.0816  0.0254  0.0854 -0.0256 -0.0442  0.0701 -0.0759 -0.0340\n",
       " -0.0195 -0.0617 -0.0435  0.0245  0.0482  0.0097 -0.1041 -0.0832  0.1015 -0.0682\n",
       "  0.0747  0.0483 -0.0779  0.0457  0.0445 -0.1047 -0.0323  0.0244 -0.0549  0.0666\n",
       "  0.0543  0.0202  0.0893 -0.0595  0.0059 -0.0034 -0.0147 -0.0933 -0.0263 -0.0697\n",
       "  0.0458 -0.0470  0.0005 -0.0564  0.0337  0.0968 -0.0582 -0.1068  0.0313  0.0371\n",
       " -0.0275  0.0149  0.0291 -0.0900 -0.0958 -0.1061 -0.0893 -0.0913  0.0732  0.0813\n",
       " -0.0434  0.0273 -0.0065 -0.0526 -0.0904 -0.0338 -0.0682  0.1067 -0.0992 -0.0235\n",
       "  0.0687 -0.0844 -0.0748  0.0279  0.0564 -0.0709  0.0060  0.0772  0.0127  0.1059\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.0836  0.0635 -0.0659  0.0173  0.0062 -0.0256 -0.0889  0.0815  0.0105  0.0979\n",
       " -0.0666  0.0404  0.0622 -0.0483 -0.0198 -0.0410 -0.0665 -0.0526 -0.1044  0.0533\n",
       " -0.0623  0.0891 -0.0939 -0.0371  0.0244  0.0256  0.0721  0.0005 -0.0949  0.0922\n",
       " -0.0839  0.0156  0.0102 -0.0968 -0.0061 -0.0934 -0.0140  0.0643 -0.0742 -0.1029\n",
       "  0.0310 -0.0084  0.0802  0.1025 -0.0997 -0.0237  0.0803 -0.0247  0.0062 -0.1074\n",
       "  0.0180 -0.0424  0.0639  0.1052 -0.1017  0.0333  0.0105 -0.0399 -0.0583 -0.1080\n",
       " -0.0973  0.0030  0.0660 -0.0361 -0.0874  0.0218 -0.0807 -0.0806 -0.0628  0.0819\n",
       " -0.0227 -0.0032 -0.0384  0.1080 -0.0562  0.0606  0.0143  0.1022  0.0885  0.0112\n",
       " -0.0130  0.0133  0.0991 -0.0826 -0.0097 -0.0236  0.0289 -0.1035 -0.0511  0.0935\n",
       "  0.0567  0.0293 -0.0760  0.0241 -0.0804 -0.0008  0.0481  0.0514 -0.0247 -0.0174\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.0978 -0.0930 -0.0796  0.0266  0.1037  0.0211 -0.0828  0.0369 -0.0219 -0.1057\n",
       " -0.0777 -0.0077  0.0039  0.0049  0.0054  0.0843  0.0556  0.0164  0.0389  0.0987\n",
       "  0.0218 -0.0738 -0.0072 -0.0551  0.0079  0.0424 -0.0869  0.0476  0.0686  0.0022\n",
       " -0.0679 -0.1001 -0.0541  0.0571  0.0917 -0.0517  0.1000 -0.0638 -0.1036  0.0013\n",
       " -0.0074  0.0205 -0.0996 -0.0016  0.0963  0.0804  0.0183  0.1087 -0.0024  0.0405\n",
       " -0.0324  0.0394  0.0528  0.0476  0.0733 -0.1043 -0.0506 -0.0776 -0.0903  0.0928\n",
       " -0.0026 -0.0493 -0.1035  0.0670  0.0398 -0.0016 -0.0672  0.0574 -0.0147  0.0531\n",
       "  0.0967 -0.0234  0.0370  0.0998  0.0112  0.0506 -0.0664  0.1023 -0.0464 -0.0101\n",
       " -0.0042  0.0555  0.0276  0.0046  0.0141  0.0743  0.0882 -0.0413  0.0628  0.0619\n",
       "  0.0476 -0.0966  0.1039  0.0788 -0.0659 -0.0299 -0.0301 -0.0574 -0.0061  0.0161\n",
       " \n",
       " Columns 50 to 59 \n",
       "  0.0179  0.0733 -0.0746 -0.0694 -0.0661  0.0492  0.0084  0.0162 -0.0459  0.0351\n",
       "  0.0390 -0.0408 -0.0175  0.0194  0.0121  0.0292  0.0806 -0.0127  0.0246 -0.0955\n",
       " -0.0163  0.0601  0.0303  0.0247  0.1069 -0.0085 -0.0728 -0.0996  0.0055  0.0672\n",
       "  0.0396  0.0273 -0.0808  0.0064 -0.0810  0.0470 -0.0184 -0.0406  0.0709  0.0952\n",
       "  0.0803  0.0111 -0.0689  0.0869  0.1078 -0.0514  0.0807 -0.0604  0.0736  0.0464\n",
       "  0.0591  0.0666 -0.0215 -0.1081 -0.0865  0.0379  0.1017  0.1016  0.0097 -0.0178\n",
       "  0.0999  0.0861  0.0508 -0.0072  0.0659  0.0217 -0.0722 -0.0377 -0.0652  0.0405\n",
       " -0.0983 -0.0117  0.1046  0.0398  0.0168  0.0978  0.0131 -0.0280 -0.0399  0.0560\n",
       "  0.0514  0.1038 -0.0131 -0.0739  0.0670  0.0029 -0.0236  0.0876 -0.0287  0.0633\n",
       "  0.0918 -0.0702 -0.0320 -0.0192  0.0005 -0.0776  0.0412 -0.0354  0.0026  0.0154\n",
       " \n",
       " Columns 60 to 69 \n",
       " -0.0348  0.0376  0.0791  0.0764  0.0623 -0.0452 -0.0105 -0.0081  0.0519 -0.0308\n",
       "  0.0314 -0.0517 -0.0358  0.0066 -0.0159  0.0333  0.0706  0.0136 -0.0878 -0.0741\n",
       " -0.0131  0.0208 -0.0503  0.0357  0.0109 -0.0442 -0.1082  0.0906  0.0853  0.0517\n",
       " -0.0361 -0.0083 -0.0642  0.0549 -0.0657 -0.0997 -0.0738  0.0885 -0.0330 -0.0143\n",
       "  0.0689 -0.0315 -0.0461  0.0118 -0.0961 -0.0284 -0.0106  0.1079  0.0929  0.0883\n",
       "  0.0749  0.0520 -0.0680 -0.0232  0.0677  0.0966  0.1060 -0.0836  0.0240  0.0905\n",
       "  0.0060 -0.0886 -0.0974  0.0339  0.0655  0.0220 -0.0594 -0.0018 -0.0468 -0.0547\n",
       "  0.0578  0.0738 -0.0769  0.0115 -0.0318 -0.0098 -0.0317  0.0979 -0.0524 -0.0914\n",
       "  0.0751 -0.0759 -0.0633 -0.0388  0.1066  0.0996  0.0241  0.0399  0.0865 -0.0014\n",
       " -0.0046 -0.0613 -0.0025 -0.0455 -0.0198  0.0491  0.0714  0.0967  0.0441 -0.0626\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.0617  0.0152  0.0986  0.0215  0.0071  0.0858  0.0631  0.0621 -0.0853  0.0178\n",
       " -0.1078 -0.0851  0.0747 -0.0996  0.0102  0.0660  0.0862  0.0482 -0.0249 -0.0365\n",
       " -0.0974 -0.0382  0.0974 -0.0998  0.0962  0.0167  0.0215  0.0735  0.1033  0.1047\n",
       "  0.0082  0.0695  0.0505  0.0509 -0.1056  0.0959  0.0436  0.0595 -0.0191 -0.0376\n",
       "  0.0133  0.0699  0.0456 -0.0290 -0.0872 -0.0406 -0.0316  0.0838 -0.0732 -0.0510\n",
       " -0.0865  0.0266  0.0182  0.0696 -0.0736 -0.0123  0.0913 -0.1071  0.0445 -0.0914\n",
       " -0.0457  0.0160 -0.0198 -0.0262 -0.1061 -0.0215 -0.0261  0.0585  0.0420  0.0051\n",
       "  0.0334 -0.0541 -0.0591 -0.0321  0.0486  0.0330 -0.0497  0.0884 -0.0906  0.0186\n",
       "  0.0487  0.0174  0.0299 -0.0617 -0.0212  0.0755 -0.0616  0.0121 -0.0723 -0.0761\n",
       " -0.0840  0.0533 -0.0881 -0.0581  0.0169 -0.0259 -0.0113  0.0349  0.0793 -0.0156\n",
       " \n",
       " Columns 80 to 83 \n",
       "  0.0776  0.0026  0.0370 -0.0412\n",
       "  0.1077  0.0933  0.0125  0.0273\n",
       "  0.0441  0.0096 -0.0720 -0.0594\n",
       " -0.0304 -0.0392 -0.0840 -0.0897\n",
       " -0.0458 -0.0905  0.0231  0.0640\n",
       "  0.0361 -0.0387 -0.0874 -0.0584\n",
       "  0.0097 -0.0730  0.0989 -0.0172\n",
       " -0.0515 -0.0581  0.0171 -0.0608\n",
       " -0.0168  0.0604 -0.0360  0.0751\n",
       " -0.0394  0.0216 -0.0787  0.0188\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   2.8322\n",
       "   0.2466\n",
       "   3.6557\n",
       "   7.5930\n",
       "   8.9530\n",
       "   2.7744\n",
       "   4.2268\n",
       "   2.9562\n",
       "  -9.3605\n",
       "   5.6671\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# create optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr= learning_rate)\n",
    "\n",
    "# in training loop\n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output,target)\n",
    "loss.backward()\n",
    "optimizer.step() ## does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
